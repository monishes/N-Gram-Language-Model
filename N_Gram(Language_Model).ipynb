{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "from nltk.probability import ConditionalFreqDist\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZrAI9JsbhBR",
        "outputId": "8f21e326-2c07-4b99-d29e-7561b11bd461"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    file = open('alice.txt', 'r')\n",
        "    text = \"\"\n",
        "    while True:\n",
        "        line = file.readline()\n",
        "        text += line\n",
        "        if not line:\n",
        "            break\n",
        "\n",
        "    # pre-process text\n",
        "    print(\"Filtering...\")\n",
        "    words = filter(text)\n",
        "    print(\"Cleaning...\")\n",
        "    words = clean(words)\n",
        "\n",
        "    # make language model\n",
        "    print(\"Making model...\")\n",
        "    model = n_gram_model(words)\n",
        "\n",
        "    print(\"Enter a phrase: \")\n",
        "    user_input = input()\n",
        "    predict(model, user_input)"
      ],
      "metadata": {
        "id": "qY6y3e6_bhox"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter(text):\n",
        "    # normalize text\n",
        "    text = (unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore'))\n",
        "    # replace html chars with ' '\n",
        "    text = re.sub('<.*?>', ' ', text)\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans(' ', ' ', string.punctuation))\n",
        "    # only alphabets and numerics\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    # replace newline with space\n",
        "    text = re.sub(\"\\n\", \" \", text)\n",
        "    # lower case\n",
        "    text = text.lower()\n",
        "    # split and join the words\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "QUdg0MxmbtlF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tokenize remaining words and perform lemmatization**"
      ],
      "metadata": {
        "id": "GUX6F_P8b0k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    wnl = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "    output = []\n",
        "    for words in tokens:\n",
        "        # lemmatize words\n",
        "        output.append(wnl.lemmatize(words))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "IwCApBIQbxQy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Make a language model using a dictionary, trigrams, and calculate word probabilities**"
      ],
      "metadata": {
        "id": "dhrPoAFYb-gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def n_gram_model(text):\n",
        "    trigrams = list(nltk.ngrams(text, 3, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
        "    # make conditional frequencies dictionary\n",
        "    cfdist = ConditionalFreqDist()\n",
        "    for w1, w2, w3 in trigrams:\n",
        "        cfdist[(w1, w2)][w3] += 1\n",
        "\n",
        "    # transform frequencies to probabilities\n",
        "    for w1_w2 in cfdist:\n",
        "        total_count = float(sum(cfdist[w1_w2].values()))\n",
        "        for w3 in cfdist[w1_w2]:\n",
        "            cfdist[w1_w2][w3] /= total_count\n",
        "\n",
        "    return cfdist"
      ],
      "metadata": {
        "id": "Oa1j7xFdb6Da"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate predictions from the Conditional Frequency Distribution dictionary (param: model), append weighted random choice to input phrase, and allow option to generate more words following the prediction"
      ],
      "metadata": {
        "id": "38nmlI-IcRvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, user_input):\n",
        "    user_input = filter(user_input)\n",
        "    user_input = user_input.split()\n",
        "\n",
        "    w1 = len(user_input) - 2\n",
        "    w2 = len(user_input)\n",
        "    prev_words = user_input[w1:w2]\n",
        "\n",
        "    # display prediction from highest to lowest maximum likelihood\n",
        "    prediction = sorted(dict(model[prev_words[0], prev_words[1]]), key=lambda x: dict(model[prev_words[0], prev_words[1]])[x], reverse=True)\n",
        "    print(\"Trigram model predictions: \", prediction)\n",
        "\n",
        "    word = []\n",
        "    weight = []\n",
        "    for key, prob in dict(model[prev_words[0], prev_words[1]]).items():\n",
        "        word.append(key)\n",
        "        weight.append(prob)\n",
        "    # picking from a weighted random probability of predictions\n",
        "    next_word = random.choices(word, weights=weight, k=1)\n",
        "    # add predicted word output to our input\n",
        "    user_input.append(next_word[0])\n",
        "    print(' '.join(user_input))\n",
        "\n",
        "    ask = input(\"Do you want to generate another word? (type 'y' for yes or 'n' for no): \")\n",
        "    if ask.lower() == 'y':\n",
        "        predict(model, str(user_input))\n",
        "    elif ask.lower() == 'n':\n",
        "        print(\"done\")\n",
        "        \n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaPIs832cIhF",
        "outputId": "71353ef0-70bb-449f-f48a-95f8200ace9c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering...\n",
            "Cleaning...\n",
            "Making model...\n",
            "Enter a phrase: \n",
            "alice said to the\n",
            "Trigram model predictions:  ['other', 'jury', 'door', 'table', 'knave', 'mock', 'gryphon', 'little', 'end', 'shore', 'beginning', 'dormouse', 'game', 'queen', 'garden', 'seaside', 'general', 'cur', 'fifth', 'puppy', 'law', 'baby', 'three', 'king', 'rosetree', 'conclusion', 'cheshire', 'duchess', 'executioner', 'croquetground', 'company', 'classic', 'whiting', 'dance', 'porpoise', 'part', 'caterpillar', 'hatter', 'head', 'tart', 'waving', 'voice', 'confused']\n",
            "alice said to the gryphon\n",
            "Do you want to generate another word? (type 'y' for yes or 'n' for no): y\n",
            "Trigram model predictions:  ['and', 'went', 'it', 'said', 'i', 'you', 'the', 'replied', 'alice', 'sat', 'half', 'answered', 'she', 'before', 'lifted', 'never', 'sighing', 'remarked', 'interrupted', 'of', 'then', 'with', 'turn', 'at', 'we', 'ive', 'that', 'do', 'added', 'in', 'a', 'how', 'well', 'hastily', 'repeated', 'only', 'they', 'whispered']\n",
            "alice said to the gryphon you\n",
            "Do you want to generate another word? (type 'y' for yes or 'n' for no): y\n",
            "Trigram model predictions:  ['first', 'advance']\n",
            "alice said to the gryphon you advance\n",
            "Do you want to generate another word? (type 'y' for yes or 'n' for no): y\n",
            "Trigram model predictions:  ['twice']\n",
            "alice said to the gryphon you advance twice\n",
            "Do you want to generate another word? (type 'y' for yes or 'n' for no): y\n",
            "Trigram model predictions:  ['each', 'set']\n",
            "alice said to the gryphon you advance twice each\n",
            "Do you want to generate another word? (type 'y' for yes or 'n' for no): y\n",
            "Trigram model predictions:  ['with']\n",
            "alice said to the gryphon you advance twice each with\n",
            "Do you want to generate another word? (type 'y' for yes or 'n' for no): y\n",
            "Trigram model predictions:  ['a']\n",
            "alice said to the gryphon you advance twice each with a\n",
            "Do you want to generate another word? (type 'y' for yes or 'n' for no): y\n",
            "Trigram model predictions:  ['sigh', 'little', 'knife', 'pair', 'sudden', 'shiver', 'table', 'barrowful', 'yelp', 'carthorse', 'kind', 'round', 'deep', 'lobster', 'bound', 'whiting', 'growl', 'great', 'soldier', 'trumpet', 'large', 'teacup', 't', 'melancholy', 'smile']\n",
            "alice said to the gryphon you advance twice each with a sigh\n",
            "Do you want to generate another word? (type 'y' for yes or 'n' for no): n\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Axz2LrJmcmnA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}